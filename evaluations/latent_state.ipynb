{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自动加载python模块，不需要手动重启kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zsongah/.conda/envs/transformer/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zsongah/tVAE_across_task_rat25_v2\n"
     ]
    }
   ],
   "source": [
    "%cd /home/zsongah/tVAE_across_task_rat25_v2 \n",
    "import torch\n",
    "from configs.config import get_config\n",
    "from data.dataset import Dataset\n",
    "from runners.stVAE_runner import stVAE_runner\n",
    "from runners.LFADS_runner import LFADS_runner\n",
    "from runners.DFINE_runner import DFINE_runner\n",
    "from runners.LDF_runner import LDF_runner\n",
    "from scipy import stats\n",
    "from evaluations.eval_utils import align_latent_mu\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| load neural data | train length: 8121, trial: 108 | test length: 2433 , trial: 26 | 32 total neurons | 16 M1 neurons | \n",
      "Checkpoint loaded from runs/LDF_025_20250402_200059/025_1MC_2020-07-16_0fold_6latent_LDF.pkl\n",
      "| load neural data | train length: 13438, trial: 141 | test length: 3814 , trial: 35 | 32 total neurons | 16 M1 neurons | \n",
      "Checkpoint loaded from runs/LDF_025_20250402_200059/025_1MC_2020-07-16_0fold_6latent_LDF.pkl\n"
     ]
    }
   ],
   "source": [
    "# settings\n",
    "model_names = ['stVAE','LFADS','DFINE','LDF'] # model folder\n",
    "# experiment_names = ['stVAE','LFADS','DFINE'] # experiment name\n",
    "run_times = ['20250401_220854','20250401_204320','20250326_095918','20250402_200059'] # rat 25 test fold 0 \n",
    "# run_times = ['20250401_213231','20250401_213323','20250401_213605'] # rat 25 test fold 1 \n",
    "# run_times = ['20250401_214759','20250401_214916','20250401_214818'] # rat 25 latent_dim 8\n",
    "rat = '025'\n",
    "latent_dim = 6\n",
    "task_1mc = '1MC'\n",
    "task_2mc = '2MC'\n",
    "day_1mc = '2020-07-16'\n",
    "day_2mc = '2020-10-05'\n",
    "test_fold = 0 \n",
    "# load model from 1MC\n",
    "load_file_prefix = f'{rat}_{task_1mc}_{day_1mc}_{test_fold}fold_' \\\n",
    "                f'{latent_dim}latent_' \n",
    "\n",
    "model_files = [\n",
    "    f'runs/{model_name}_{rat}_{run_time}/{load_file_prefix}{model_name}.{\"pkl\" if model_name == \"LDF\" else \"pth\"}'\n",
    "    for model_name, run_time in zip(model_names, run_times)\n",
    "]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# get model results\n",
    "tasks = [task_1mc, task_2mc]\n",
    "days = [day_1mc, day_2mc]\n",
    "model_results = {name: {} for name in model_names}\n",
    "for model_file, model_name in zip(model_files, model_names):\n",
    "    config_file = model_name\n",
    "    \n",
    "    for day, task in zip(days, tasks):\n",
    "        config = get_config(config_file, [\n",
    "                'DATA.RAT', rat,\n",
    "                'DATA.TASK', task,\n",
    "                'DATA.DAY', day, # can not use number_number \n",
    "                'DATA.TEST_FOLD', test_fold,\n",
    "                'MODEL.LATENT_DIM', latent_dim,\n",
    "            ])\n",
    "        dataset = Dataset(config, rat, day, task, test_fold, device)\n",
    "        if model_name == 'stVAE':\n",
    "            runner = stVAE_runner(config, dataset, model_name) \n",
    "        elif model_name == 'LFADS':\n",
    "            runner = LFADS_runner(config, dataset, model_name)\n",
    "        elif model_name == 'DFINE':\n",
    "            runner = DFINE_runner(config, dataset, model_name)\n",
    "        elif model_name == 'LDF':\n",
    "            runner = LDF_runner(config, dataset, model_name)\n",
    "\n",
    "        if model_name == 'LDF':\n",
    "            runner.load_model(model_file)\n",
    "        else:\n",
    "            checkpoint = torch.load(model_file,map_location=device)\n",
    "            runner.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            runner.model.eval()\n",
    "        result_test = runner.evaluate()\n",
    "        result_train = runner.eval_train()\n",
    "        model_results[model_name][task] = {\n",
    "            'result_test': result_test,\n",
    "            'result_train': result_train\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_latent_state ={model:{} for model in model_names}\n",
    "for model_name in model_names:\n",
    "     for task in tasks:\n",
    "        latent_mu = stats.zscore(model_results[model_name][task]['result_train']['latent_mu'],axis=0)\n",
    "        actions = model_results[model_name][task]['result_train']['actions']\n",
    "        scaled_latent_state[model_name][task], len_start, len_press, len_release, len_after_release, trial_types = align_latent_mu(actions, latent_mu)\n",
    "        \n",
    "cue_start = len_start-1\n",
    "press_lever = len_start + len_press - 1\n",
    "release_lever = len_start + len_press + len_release - 1\n",
    "trial_num, trial_length, feature_num = scaled_latent_state['stVAE']['2MC'].shape\n",
    "start_point = cue_start\n",
    "end_point = press_lever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_HIGH_LEVER = '#D55E00'  # 深橙色，高杠杆\n",
    "COLOR_LOW_LEVER = '#0072B2'  # 海蓝色，低杠杆\n",
    "COLOR_REST = '#1B9E77'  # 翡翠绿\n",
    "COLOR_OTHER = '#A9A9A9'  # 灰色\n",
    "COLOR_HIGH_LEVER_TRAJ = '#E69F00'  # 橙色，高杠杆轨迹（稍微浅一些）\n",
    "COLOR_LOW_LEVER_TRAJ = '#56B4E9'   # 浅蓝色，低杠杆轨迹\n",
    "\n",
    "def plot_MC1_PCA_for_model(scaled_latent, title, ax):\n",
    "    \"\"\"\n",
    "    对 MC1 (1MC) 数据进行 PCA 分解后绘图，\n",
    "    scaled_latent: shape 为 (trial_num, trial_length, latent_dim)\n",
    "    返回 PCA 对象、降维后的所有试次数据以及 averaged trial（均值轨迹）\n",
    "    \"\"\"\n",
    "    # 将数据拉平成二维：(trial_num * trial_length, latent_dim)\n",
    "    latent_flat = np.reshape(scaled_latent, (-1, scaled_latent.shape[-1]))\n",
    "    pca = PCA(n_components=2)\n",
    "    latent_pca_flat = pca.fit_transform(latent_flat)\n",
    "    # 恢复回 (trial_num, trial_length, 2)\n",
    "    latent_pca = latent_pca_flat.reshape(scaled_latent.shape[0], scaled_latent.shape[1], -1)\n",
    "    \n",
    "    # 计算 averaged trial （对所有 trial 在时间维度取均值）\n",
    "    averaged_trial = np.mean(latent_pca, axis=0)\n",
    "    \n",
    "    # 对每个 trial 绘图\n",
    "    for i in range(latent_pca.shape[0]):\n",
    "        trial_data = latent_pca[i]\n",
    "        # 绘制 “Other” 区间：由 cue_start 到 press_lever，以及 release_lever 之后\n",
    "        other_points = np.vstack(( trial_data[cue_start:press_lever], trial_data[release_lever:] ))\n",
    "        ax.scatter(other_points[:, 0], other_points[:, 1], c=COLOR_OTHER, s=20, alpha=0.2, \n",
    "                   label='Other' if i == 0 else '')\n",
    "        # 绘制 “Rest” 部分：从 trial 开始至 cue_start\n",
    "        rest_points = trial_data[:cue_start]\n",
    "        ax.scatter(rest_points[:, 0], rest_points[:, 1], c=COLOR_REST, s=20, alpha=1, \n",
    "                   label='Rest' if i == 0 else '')\n",
    "        # 绘制 “Press Lever” 部分：从 press_lever 到 release_lever（高杠杆）\n",
    "        press_points = trial_data[press_lever:release_lever]\n",
    "        ax.scatter(press_points[:, 0], press_points[:, 1], c=COLOR_HIGH_LEVER, s=20, alpha=1, \n",
    "                   label='High Lever' if i == 0 else '')\n",
    "    \n",
    "    # 绘制 averaged trial 的轨迹线（高杠杆轨迹）\n",
    "    ax.plot(averaged_trial[start_point:end_point+1, 0], averaged_trial[start_point:end_point+1, 1],\n",
    "            c=COLOR_HIGH_LEVER_TRAJ, linewidth=5, label='Averaged High Trial')\n",
    "    # 标记 averaged trial 的起点和终点\n",
    "    ax.scatter(averaged_trial[cue_start, 0], averaged_trial[cue_start, 1],\n",
    "               c=COLOR_REST, s=100, marker='o', edgecolors='black', zorder=5, label='Start Point')\n",
    "    ax.scatter(averaged_trial[press_lever, 0], averaged_trial[press_lever, 1],\n",
    "               c=COLOR_HIGH_LEVER, s=100, marker='^', edgecolors='black', zorder=5, label='End Point')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_xlabel('PC 1', fontsize=12)\n",
    "    ax.set_ylabel('PC 2', fontsize=12)\n",
    "    \n",
    "    return pca, latent_pca, averaged_trial\n",
    "\n",
    "def plot_MC2_in_MC1_PCA(scaled_latent, trial_types, title, ax, pca):\n",
    "    \"\"\"\n",
    "    将 MC2 (2MC) 数据映射到 MC1 得到的 PCA 平面上绘图\n",
    "    scaled_latent: MC2 数据，shape 同样为 (trial_num, trial_length, latent_dim)\n",
    "    trial_types: 每个 trial 对应的类型（例如：1 表示 high、-1 表示 low）\n",
    "    \"\"\"\n",
    "    latent_flat = np.reshape(scaled_latent, (-1, scaled_latent.shape[-1]))\n",
    "    latent_pca_flat = pca.transform(latent_flat)\n",
    "    latent_pca = latent_pca_flat.reshape(scaled_latent.shape[0], scaled_latent.shape[1], -1)\n",
    "    \n",
    "    # 分离 high trial 和 low trial（注意：trial_types 是一维数组，每个 trial 对应一个标签）\n",
    "    high_indices = np.array(trial_types) == 1\n",
    "    low_indices = np.array(trial_types) == -1\n",
    "    averaged_high  = np.mean(latent_pca[high_indices.flatten()], axis=0)\n",
    "    averaged_low   = np.mean(latent_pca[low_indices.flatten()], axis=0)\n",
    "    \n",
    "    # 绘制每个 trial 的点\n",
    "    for i in range(latent_pca.shape[0]):\n",
    "        trial_data = latent_pca[i]\n",
    "        this_type = trial_types[i]\n",
    "        # 绘制 “Other” 点\n",
    "        other_points = np.vstack((trial_data[cue_start:press_lever], trial_data[release_lever:]))\n",
    "        ax.scatter(other_points[:, 0], other_points[:, 1], c=COLOR_OTHER, s=20, alpha=0.2)\n",
    "        # 绘制 “Rest” 点\n",
    "        rest_points = trial_data[:cue_start]\n",
    "        ax.scatter(rest_points[:, 0], rest_points[:, 1], c=COLOR_REST, s=20, alpha=1)\n",
    "        # 绘制 “Press Lever” 点，根据 trial 类型着色\n",
    "        press_points = trial_data[press_lever:release_lever]\n",
    "        if this_type == 1:\n",
    "            ax.scatter(press_points[:, 0], press_points[:, 1], c=COLOR_HIGH_LEVER, s=20, alpha=1)\n",
    "        elif this_type == -1:\n",
    "            ax.scatter(press_points[:, 0], press_points[:, 1], c=COLOR_LOW_LEVER, s=20, alpha=1)\n",
    "    \n",
    "    # 绘制 averaged high trial 的轨迹线\n",
    "    ax.plot(averaged_high[start_point:end_point+1, 0], averaged_high[start_point:end_point+1, 1],\n",
    "            c=COLOR_HIGH_LEVER_TRAJ, linewidth=5)\n",
    "    ax.scatter(averaged_high[cue_start, 0], averaged_high[cue_start, 1],\n",
    "               c=COLOR_REST, s=100, marker='o', edgecolors='black', zorder=5)\n",
    "    ax.scatter(averaged_high[press_lever, 0], averaged_high[press_lever, 1],\n",
    "               c=COLOR_HIGH_LEVER, s=100, marker='^', edgecolors='black', zorder=5)\n",
    "    \n",
    "    # 绘制 averaged low trial 的轨迹线\n",
    "    ax.plot(averaged_low[start_point:end_point+1, 0], averaged_low[start_point:end_point+1, 1],\n",
    "            c=COLOR_LOW_LEVER_TRAJ, linewidth=5)\n",
    "    ax.scatter(averaged_low[cue_start, 0], averaged_low[cue_start, 1],\n",
    "               c=COLOR_REST, s=100, marker='o', edgecolors='black', zorder=5)\n",
    "    ax.scatter(averaged_low[press_lever, 0], averaged_low[press_lever, 1],\n",
    "               c=COLOR_LOW_LEVER, s=100, marker='^', edgecolors='black', zorder=5)\n",
    "    \n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_xlabel('PC 1', fontsize=12)\n",
    "    ax.set_ylabel('PC 2', fontsize=12)\n",
    "    \n",
    "    return latent_pca\n",
    "\n",
    "# =============================================================================\n",
    "# 生成2行n列 (n=模型个数) 的图\n",
    "# 第一行绘制 MC1 数据的 PCA ，第二行绘制 MC2 数据在该 PCA 平面中的投影\n",
    "# =============================================================================\n",
    "\n",
    "n_models = len(model_names)\n",
    "\n",
    "# 创建子图：2行，每个模型一列\n",
    "fig, axes = plt.subplots(2, n_models, figsize=(5 * n_models, 10))\n",
    "\n",
    "for i, model_name in enumerate(model_names):\n",
    "    # 使用该模型 1MC 与 2MC 下的对齐后数据\n",
    "    latent_MC1 = scaled_latent_state[model_name]['1MC']\n",
    "    latent_MC2 = scaled_latent_state[model_name]['2MC']\n",
    "    \n",
    "    # 第一行：MC1 数据进行 PCA 得到 2D 表示\n",
    "    if n_models > 1:\n",
    "        ax1 = axes[0, i]\n",
    "    else:\n",
    "        ax1 = axes[0]\n",
    "    title1 = f\"{model_name} (MC1)\"\n",
    "    pca, latent_MC1_pca, avg_MC1 = plot_MC1_PCA_for_model(latent_MC1, title1, ax1)\n",
    "    \n",
    "    # 第二行：MC2 数据映射到 MC1 的 PCA 平面上\n",
    "    if n_models > 1:\n",
    "        ax2 = axes[1, i]\n",
    "    else:\n",
    "        ax2 = axes[1]\n",
    "    title2 = f\"{model_name} (MC2)\"\n",
    "    plot_MC2_in_MC1_PCA(latent_MC2, trial_types, title2, ax2, pca)\n",
    "    # 获取当前列的上下图的坐标范围\n",
    "    x_min = min(ax1.get_xlim()[0], ax2.get_xlim()[0])\n",
    "    x_max = max(ax1.get_xlim()[1], ax2.get_xlim()[1])\n",
    "    y_min = min(ax1.get_ylim()[0], ax2.get_ylim()[0])\n",
    "    y_max = max(ax1.get_ylim()[1], ax2.get_ylim()[1])\n",
    "    \n",
    "    # 统一当前列的上下图坐标范围\n",
    "    ax1.set_xlim(x_min, x_max)\n",
    "    ax1.set_ylim(y_min, y_max)\n",
    "    ax2.set_xlim(x_min, x_max)\n",
    "    ax2.set_ylim(y_min, y_max)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
